using Distributions
using LogExpFunctions

import Distributions: logpdf

# The LED for alignment
struct LengthEquilibriumDistribution <: DiscreteUnivariateDistribution

    lp_0::Real
    lp_geom_rate::Real
    function LengthEquilibriumDistribution(λ::Real, μ::Real, r::Real)
        lp_0 = log1mexp(log(λ) - log(μ))
        lp_geom_rate = lp_0 + log1mexp(log(r))
        new(lp_0, lp_geom_rate)
    end
end

const LED = LengthEquilibriumDistribution

function Distributions.rand(rng::AbstractRNG, d::LED)
    is_0 = rand(rng, Bernoulli(exp(d.lp_0)))
    if is_0
        return 0
    else
        return 1+rand(rng, Geometric(exp(d.lp_geom_rate)))
    end
end

function Distributions.logpdf(d::LED, n::Integer)
    if n == 0
        return d.lp_0
    else
        return log1mexp(d.lp_0) + (n-1)*log1mexp(d.lp_geom_rate) + d.lp_geom_rate
    end
end




# ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
# Distribution over unconditioned alignments
# generated by a pairhmm model

# ℙ[M | τ]
struct AlignmentDistribution <: DiscreteUnivariateDistribution
    τ::TKF92  # alignment model
    max_length::Integer
    function AlignmentDistribution(τ::TKF92; max_length=3000)
         new(τ, max_length)
    end
end

eltype(d::AlignmentDistribution) = Integer
length(d::AlignmentDistribution) = d.max_length

function alignment_to_tkf92state_ids(M::Alignment, τ::TKF92)
    s = START_INDEX
    D = num_descendants(τ)
    flags = align_state_flags[D][s]
    state_ids = Int[]
    for col ∈ M
        anc_value = col[1]
        desc_values = col[2:end]
        if anc_value == 1
            # scenario changes
            state = gen_ancestor_state(desc_values)
            flags .= desc_values
        else
            # scenario hasn't changed
            state = gen_descendant_state(desc_values, flags)
        end
        q = state_ids_dict(τ)[state]
        s = q
        push!(state_ids, s)
    end
    return state_ids
end

function tkf92state_ids_to_alignment(ids::AbstractVector{<:Integer}, τ::TKF92)
    my_ids = copy(ids)
    return Alignment(hcat(state_align_cols(τ)[my_ids[my_ids .!= 0]]...))
end

function Alignment(state_ids::AbstractVector{<:Integer}, ids::AbstractVector{<:Integer}, τ::TKF92)
    a = tkf92state_ids_to_alignment(state_ids, τ)
    return Alignment(data(a), ids)
end

function Alignment(state_ids::AbstractVector{<:Integer}, τ::TKF92)
    tkf92state_ids_to_alignment(state_ids, τ)
end

function Distributions.logpdf(d::AlignmentDistribution, ids::AbstractArray{<:Integer})
    return _logpdf(d, ids)
end


function _logpdf(d::AlignmentDistribution, ids::AbstractArray{<:Integer})
    τ = d.τ
    A = transmat(τ)

    s = START_INDEX
    res = 0
    for q ∈ ids[ids .!= 0]
        res += A[s, q]
        s = q
    end
    res += A[s, END_INDEX]
    return res
end

function _rand!(rng::AbstractRNG, d::AlignmentDistribution,
                ids::AbstractVector{<:Integer})
    M = similar(ids, num_descendants(d.τ)+1, length(ids))
    model = d.τ
    max_length = d.max_length
    P = exp.(transmat(model))

    length = max_length + 1
    seq_lengths = fill(0, size(d, 1))

    # reject samples which exceed match length or ones which have null sequences
    while length > max_length || any(seq_lengths .< 3)
        i = 1
        s = START_INDEX
        while s != END_INDEX
            s = rand(rng, Categorical(vec(P[s, :])))
            col = state_align_cols(model)[s]

            if !model.known_ancestor && s == no_survivors_ancestor_id(model)
                l = 1 + rand(rng, Geometric(1 - model.full_del_rate))
                M[:, i:(i+l-1)] .= col
                ids[i:(i+l-1)] .= s
                i += l
            elseif s != END_INDEX
                M[:, i] .= col
                ids[i] = s
                i += 1
            end
        end
        length = i-1
        seq_lengths = [count(M[j, 1:length] .== 1) for j ∈ eachindex(seq_lengths)]
    end
    M[:, (length+1):end] .= 0
    ids[(length+1):end] .= 0

    return ids
end


# ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
# ℙ[M | X, Y, τ]
struct ConditionedAlignmentDistribution <: DiscreteMultivariateDistribution
    τ::TKF92 # alignment model
    α::AbstractArray{<:Real} #DP matrix for conditional alignment sampling/pdf computation
    max_length::Integer
    function ConditionedAlignmentDistribution(τ::TKF92,
                                              α::AbstractArray{<:Real};
                                              max_length=3000)
        return new(τ, α, max_length)
    end

end

length(d::ConditionedAlignmentDistribution) = d.max_length
eltype(d::ConditionedAlignmentDistribution) = Integer

# lℙ[M_XY | X, Y]

function Distributions.logpdf(d::ConditionedAlignmentDistribution, ids::AbstractArray{<:Integer})
    return _logpdf(d, ids)
end

function _logpdf(d::ConditionedAlignmentDistribution, ids::AbstractArray{<:Integer})
    a = tkf92state_ids_to_alignment(ids, d.τ)
    logp = _backward_logpdf(d.α, d.τ, a)
    return logp
end

function _rand!(rng::AbstractRNG, d::ConditionedAlignmentDistribution,
                ids::AbstractArray{<:Integer})
    p = NaN
    ids .= 0
    while isnan(p)
        alignment = _backward_sampling(rng, d.α, d.τ)
        raw_ids = alignment_to_tkf92state_ids(alignment, d.τ)
        p = logpdf(d, raw_ids)
        ids .= 0
        ids[1:length(raw_ids)] .= raw_ids
    end

    return ids
end

function _backward_logpdf(α::AbstractArray{<:Real}, model::TKF92, M::Alignment)
    end_corner = size(α)[1:end-1] # N_X + 1 by N_Y + 1
    A = transmat(model)
    state_ids = alignment_to_tkf92state_ids(M, model)
    res = 0

    # the log probability of doing a backstep to a state from current state
    lps = similar(α, num_states(model))

    # first, step back from the END state
    s = state_ids[end]
    lps .= A[:, END_INDEX] .+ α[end_corner..., :]
    res += lps[s] - logsumexp(lps)

    curr_αind = end_corner

    # keep doing back steps until the START state is reached
    for q ∈ [reverse(state_ids[1:end-1]); START_INDEX]
        state = state_values(model)[s]

        # special case - if ancestor not known, cannot keep track of this index
        if !model.known_ancestor && s == no_survivors_ancestor_id(model) && s == q
            res += log(model.full_del_rate)
        else
            # backtracking through α
            prev_αind = curr_αind .- state
            lps .= A[:, s] .+ α[prev_αind..., :] .- α[curr_αind..., s]
            res += lps[q] - logsumexp(lps)
            curr_αind = prev_αind
        end

        s = q
    end

    return res
end

function _backward_sampling(rng::AbstractRNG,
                            α::AbstractArray{<:Real}, model::TKF92)

    end_corner = size(α)[1:end-1] # N_X + 1 by N_Y + 1
    A = transmat(model)

    # the log probability of doing a backstep to a state from current state
    lps = similar(α, num_states(model))

    # first, step back from the END state
    lps .= A[:, END_INDEX] .+ α[end_corner..., :]
    lps .-= logsumexp(lps)

    s = rand(rng, Categorical(exp.(lps)))
    curr_αind = end_corner
    align_cols = Domino[]

    # keep doing back steps until the START state is reached
    while s != START_INDEX
        col = state_align_cols(model)[s]
        state = state_values(model)[s]
        # if ancestor unknown, cannot keep track of index
        if !model.known_ancestor && s == no_survivors_ancestor_id(model)
            l = 1 + rand(rng, Geometric(1 - model.full_del_rate))
            append!(align_cols, fill(col, l))
        else
            push!(align_cols, col)
        end

        # probabilistic backtracking through α
        prev_αind = curr_αind .- state
        lps .= A[:, s] .+ α[prev_αind..., :] .- α[curr_αind..., s]
        lps .-= logsumexp(lps)
        curr_αind = prev_αind

        s = rand(rng, Categorical(exp.(lps)))
    end
    return Alignment(hcat(reverse(align_cols)...))
end
