struct EvolHMM <: ContinuousMatrixDistribution
    M::Integer                      # Total alignment length M = sum(lengths)
    lengths::AbstractVector{Int}
    ðš¯::AbstractProcess
    A::AbstractMatrix{Real}
    t::Real

    Î±::Array{Real}
end

function EvolHMM(n, m, A, sub, diff, t)
    Î± = Array{Real}(undef, n+2, m+2, 4)
    return PairHMM(n, m, A, sub, diff, t, Î±)
end

function _logpdf(d::EvolHMM, x::AbstractMatrix{<:Real})

    return forward!(d.Î±, x[1:3, 1:d.n], x[4:6, 1:d.m], d.A, d.sub, d.diff, d.t)
end

size(d::PairHMM) = (6, max(d.n, d.m))

length(d::PairHMM) = product(size(d))





function forward!(Î±, A, observations)
    Î± = fill!(Î±, -Inf)
    # Initial state
    Î±[2, 2, START] = 0

    # Recursion
    for indices âˆˆ grid, s âˆˆ states
        domino = onehot[s]
        prev_indices = _prev_indices(indices, domino)
        Î±[s, indices...] = _lp(domino, indices, observations) + logsumexp([A[q, s] + Î±[q, (indices - domino)...]])
    end

    # Finally need to enter the END state to complete the chain
    logp = logsumexp([Î±[s, end_corner...] + A[s, END] for s in states])

    return logp
end
#todo compute gradient of forward w.r.t A and observations

function backward_sampling(Î±, A)
    n_x, n_y = size(Î±) .- 2
    states = 1:4
    logp = logsumexp([Î±[n_x+2, n_y+2, q] + A[q, END] for q in states])

    s = rand(Categorical(exp.([Î±[n_x+2, n_y+2, q] + A[q, END] - logp for q in states])))
    indices =

    alignment = []
    while s != START
        domino = onehot[s]
        push!(alignment, domino)

        new_indices = indices - onehot[s]

        lps = [A[q, s] + Î±[q, new_indices...] - Î±[s, indices...] for q in states]

        indices = new_indices
        s = rand(Categorical(normalize(exp.([lpS, lpM, lpD, lpI]), 1)))
    end
    return reverse(alignment)
end
